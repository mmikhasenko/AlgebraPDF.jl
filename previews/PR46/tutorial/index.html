<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tutorial · AlgebraPDF</title><meta name="title" content="Tutorial · AlgebraPDF"/><meta property="og:title" content="Tutorial · AlgebraPDF"/><meta property="twitter:title" content="Tutorial · AlgebraPDF"/><meta name="description" content="Documentation for AlgebraPDF."/><meta property="og:description" content="Documentation for AlgebraPDF."/><meta property="twitter:description" content="Documentation for AlgebraPDF."/><meta property="og:url" content="https://mmikhasenko.github.io/AlgebraPDF.jl/stable/tutorial/"/><meta property="twitter:url" content="https://mmikhasenko.github.io/AlgebraPDF.jl/stable/tutorial/"/><link rel="canonical" href="https://mmikhasenko.github.io/AlgebraPDF.jl/stable/tutorial/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">AlgebraPDF</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Tutorial</a><ul class="internal"><li><a class="tocitem" href="#Function-With-Parameters"><span>Function With Parameters</span></a></li><li><a class="tocitem" href="#Predefined-function"><span>Predefined function</span></a></li><li><a class="tocitem" href="#Normalization"><span>Normalization</span></a></li><li><a class="tocitem" href="#Summation-of-Functions"><span>Summation of Functions</span></a></li><li><a class="tocitem" href="#Sampling-from-the-model"><span>Sampling from the model</span></a></li><li><a class="tocitem" href="#Likelihood-and-Model-Fitting"><span>Likelihood and Model Fitting</span></a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tutorial</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tutorial</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/mmikhasenko/AlgebraPDF.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/mmikhasenko/AlgebraPDF.jl/blob/main/docs/src/tutorial_lit.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Tutorial"><a class="docs-heading-anchor" href="#Tutorial">Tutorial</a><a id="Tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#Tutorial" title="Permalink"></a></h1><p>This tutorial guides the user through the basic example of creating a density function which is a sum of a gaussian signal peak, and exponential background, sampling from the distribution, and optimizating its parameters with an unbinned fit.</p><pre><code class="language-julia hljs">using AlgebraPDF, AlgebraPDF.Parameters
using LinearAlgebra, Optim

using Random
Random.seed!(100)

using Plots
theme(:wong, frame=:box, xlab=&quot;x&quot;, lab=&quot;&quot;, minorticks=true,
    guidefontvalign=:top, guidefonthalign=:right,
    xlim=(:auto, :auto), ylim=(0, :auto), grid=false)</code></pre><h2 id="Function-With-Parameters"><a class="docs-heading-anchor" href="#Function-With-Parameters">Function With Parameters</a><a id="Function-With-Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Function-With-Parameters" title="Permalink"></a></h2><p>The package provides a standard wrapper of a function with parameters <code>f(x;p)</code>, where <code>x</code> is function variable, <code>p</code> is a structure that holds parameters with their names. The simplest and the most common case is where <code>x</code> would be a number, and <code>p</code> is a named tuple. For example,</p><pre><code class="language-julia hljs">myf(x; p=(a=1.1, b=2.2)) = x * p.a + p.b / x;</code></pre><p>The module introduces a type <code>FunctionWithParameters</code>, which intends to behave like the <code>myf</code> from the user prospective.</p><h2 id="Predefined-function"><a class="docs-heading-anchor" href="#Predefined-function">Predefined function</a><a id="Predefined-function-1"></a><a class="docs-heading-anchor-permalink" href="#Predefined-function" title="Permalink"></a></h2><p>The gaussian function is constructed calling a specific type <code>FGauss</code>, and giving a tuple of parameters with their default values</p><pre><code class="language-julia hljs">gaussian = FGauss((μ=1.1, σ=0.9))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}((μ = 1.1, σ = 0.9))</code></pre><p>It is on of the predefined examples of functions with parameters, <code>FGauss &lt;: AbstractFunctionWithParameters</code>. The object is callable like a regular function</p><pre><code class="language-julia hljs">gaussian(1.1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.44326920044603635</code></pre><p>when array is passed, the function is broadcasted</p><pre><code class="language-julia hljs">gaussian(-1.8:0.9:1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 0.002466547098396111
 0.037526278928078506
 0.21003279415923584
 0.43245829907971817</code></pre><p>Default values of the parameters can be accessed with <code>pars</code>, and <code>freepars</code> method.</p><pre><code class="language-julia hljs">pars(gaussian)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(μ = 1.1, σ = 0.9)</code></pre><p>One can provide the key argument <code>p</code> with the named tuple of parameters. These tuple is always used instread of the default values.</p><pre><code class="language-julia hljs">gaussian(0.0; p=(; μ=1.1, σ=0.9))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.21003279415923584</code></pre><p>The parameters can be adjusted</p><pre><code class="language-julia hljs">gaussian(0.0; p=(; μ=0.0, σ=1.9))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.20996962126391197</code></pre><p>Similar to the regular fuction, the object can be plotted.</p><pre><code class="language-julia hljs">plot(gaussian, -4, 7, fill=0, α=0.8)
savefig(&quot;gaussian.pdf&quot;)</code></pre><p><a href="../gaussian.pdf"><img src="../gaussian.svg" alt="gaussian"/></a></p><p>Exponential function is another lineshape defined in the package. We are using the expnential distribution with a slope <code>α</code> to define the background to our gaussian signal.</p><pre><code class="language-julia hljs">exponential = FExp((; α=-0.2))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">FExp{NamedTuple{(:α,), Tuple{Float64}}}((α = -0.2,))</code></pre><h2 id="Normalization"><a class="docs-heading-anchor" href="#Normalization">Normalization</a><a id="Normalization-1"></a><a class="docs-heading-anchor-permalink" href="#Normalization" title="Permalink"></a></h2><p>To turn an arbitrary function to the probability density, one need to introduce normalization. This is done by attaching the range (support) to the function.</p><pre><code class="language-julia hljs">nGaussian = Normalized(gaussian, (-4, 7))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Normalized{FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}, Tuple{Int64, Int64}}(FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}((μ = 1.1, σ = 0.9)), (-4, 7))</code></pre><p>The same is archived with the pipeline.</p><pre><code class="language-julia hljs">@assert nGaussian == gaussian |&gt; Normalized((-4, 7))</code></pre><p>The normalized object has the call method regular function. The normalization is computed on fly. It is constly for a single-value call.</p><pre><code class="language-julia hljs">nGaussian(1.1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.4432692036853712</code></pre><p>When calling on iterable collection, the normalization is computed once.</p><pre><code class="language-julia hljs">nGaussian(-1.8:0.9:1)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4-element Vector{Float64}:
 0.002466547116421212
 0.03752627920231408
 0.21003279569411928
 0.43245830224004883</code></pre><p>As before, the parameters can be updates by passing a named tuple</p><pre><code class="language-julia hljs">nGaussian(0.0; p=(; μ=1.1, σ=0.9))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.21003279569411928</code></pre><p>For plotting of the normalized function, one does not need to specify the range.</p><pre><code class="language-julia hljs">plot(nGaussian, fill=0, α=0.7)
savefig(&quot;nGaussian.pdf&quot;)</code></pre><p><a href="../nGaussian.pdf"><img src="../nGaussian.svg" alt="nGaussian"/></a></p><p>Analogously,</p><pre><code class="language-julia hljs">nExponent = exponential |&gt; Normalized((-4, 7))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Normalized{FExp{NamedTuple{(:α,), Tuple{Float64}}}, Tuple{Int64, Int64}}(FExp{NamedTuple{(:α,), Tuple{Float64}}}((α = -0.2,)), (-4, 7))</code></pre><h2 id="Summation-of-Functions"><a class="docs-heading-anchor" href="#Summation-of-Functions">Summation of Functions</a><a id="Summation-of-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Summation-of-Functions" title="Permalink"></a></h2><p>Now, we can explore how to sum different types of functions or distributions. Summing functions is essential part of the package functionality that allows one to model more complex distributions.</p><p>Here, we create a model that is a sum of the previously defined normalized exponential function and the normalized Gaussian function.</p><pre><code class="language-julia hljs">model = FSum([nExponent, nGaussian], (N1=0.85, N2=0.15))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">FSum{Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters, 2, NamedTuple{(:N1, :N2), Tuple{Float64, Float64}}}(Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters[Normalized{FExp{NamedTuple{(:α,), Tuple{Float64}}}, Tuple{Int64, Int64}}(FExp{NamedTuple{(:α,), Tuple{Float64}}}((α = -0.2,)), (-4, 7)), Normalized{FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}, Tuple{Int64, Int64}}(FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}((μ = 1.1, σ = 0.9)), (-4, 7))], (N1 = 0.85, N2 = 0.15))</code></pre><p>The sum of functions, is an object of type <code>FSum</code>, that hold a list of functions and their weights in static vectors of equal sizes. There is an alternative way to formulate an equivalent model</p><pre><code class="language-julia hljs">@assert model == nExponent * (N1=0.85,) + nGaussian * (N2=0.15,)</code></pre><p>where the product of the function with a named tuple return <code>FSum</code> object. The summation between two <code>FSum</code> objects is defined. Complementary, individual components with their weight can be accessed by indexing the <code>FSum</code> object as in the following protting code.</p><pre><code class="language-julia hljs">begin
    plot(model)
    plot!(model[1], ls=:dash, lab=&quot;background&quot;)
    plot!(model[2], fill=0, lab=&quot;signal&quot;)
end
savefig(&quot;model_components.pdf&quot;)</code></pre><p><a href="../model_components.pdf"><img src="../model_components.svg" alt="Model and Components"/></a></p><h2 id="Sampling-from-the-model"><a class="docs-heading-anchor" href="#Sampling-from-the-model">Sampling from the model</a><a id="Sampling-from-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#Sampling-from-the-model" title="Permalink"></a></h2><p>Sampling from a model is a key operation in statistical modeling. <code>AlgebraPDF.jl</code> implements sampling through the numerical Inversion Method.</p><p>Here, we sample data points from our model.</p><pre><code class="language-julia hljs">@time data = AlgebraPDF.rand(model, 10_000)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">10000-element Vector{Float64}:
 -3.31363508153481
  0.43447564485962653
 -3.745754980204587
  2.9827251235352814
 -0.3309369330264057
  1.3895179840798346
 -2.0730431973848535
 -2.601550355863054
  3.2418979163154678
  1.0415275977312637
  ⋮
 -2.6897096000868306
  3.068596433247254
  2.371365572747345
  1.7739486408818284
  5.870817862622404
  4.142552947014096
 -2.1675924554448596
  6.892216385373105
 -0.5515063618655209</code></pre><p>Plotting the sampled data as a histogram gives us a visual representation of the distribution.</p><pre><code class="language-julia hljs">stephist(data, bins=100)
savefig(&quot;sampled_data_histogram.pdf&quot;)</code></pre><p><a href="../sampled_data_histogram.pdf"><img src="../sampled_data_histogram.svg" alt="Sampled Data Histogram"/></a></p><p>An equidistant grid is used. Adjusting the grid size for sampling can impact the sampling process, check <code>generate</code> method for details.</p><h2 id="Likelihood-and-Model-Fitting"><a class="docs-heading-anchor" href="#Likelihood-and-Model-Fitting">Likelihood and Model Fitting</a><a id="Likelihood-and-Model-Fitting-1"></a><a class="docs-heading-anchor-permalink" href="#Likelihood-and-Model-Fitting" title="Permalink"></a></h2><p>The concept of unbinned likelihood is central to many statistical models. In <code>AlgebraPDF.jl</code>, the negative log-likelihood is implemented. Creating a negative log-likelihood function for our model and data.</p><pre><code class="language-julia hljs">nll = NegativeLogLikelihood(model, data)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">NegativeLogLikelihood{FSum{Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters, 2, NamedTuple{(:N1, :N2), Tuple{Float64, Float64}}}, Vector{Float64}}(FSum{Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters, 2, NamedTuple{(:N1, :N2), Tuple{Float64, Float64}}}(Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters[Normalized{FExp{NamedTuple{(:α,), Tuple{Float64}}}, Tuple{Int64, Int64}}(FExp{NamedTuple{(:α,), Tuple{Float64}}}((α = -0.2,)), (-4, 7)), Normalized{FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}, Tuple{Int64, Int64}}(FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}((μ = 1.1, σ = 0.9)), (-4, 7))], (N1 = 0.85, N2 = 0.15)), [-3.31363508153481, 0.43447564485962653, -3.745754980204587, 2.9827251235352814, -0.3309369330264057, 1.3895179840798346, -2.0730431973848535, -2.601550355863054, 3.2418979163154678, 1.0415275977312637  …  -2.824345540973799, -2.6897096000868306, 3.068596433247254, 2.371365572747345, 1.7739486408818284, 5.870817862622404, 4.142552947014096, -2.1675924554448596, 6.892216385373105, -0.5515063618655209], -10000.0)</code></pre><p>Evaluating the negative log-likelihood gives us an idea of how well the model fits the data. The negative log likelihood function depends only on the model parameters, not on the variable <code>x</code>.</p><pre><code class="language-julia hljs">nll(1.0), nll(0.0), nll(())</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(22257.825216004276, 22257.825216004276, 22257.825216004276)</code></pre><p>The extended version adds a Poisson factor for the total number of events with expectation given by the norm of the model, constraining the model normalization to the number of size of the data sample.</p><pre><code class="language-julia hljs">ext = Extended(nll)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Extended{FSum{Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters, 2, NamedTuple{(:N1, :N2), Tuple{Float64, Float64}}}}(NegativeLogLikelihood{FSum{Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters, 2, NamedTuple{(:N1, :N2), Tuple{Float64, Float64}}}, Vector{Float64}}(FSum{Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters, 2, NamedTuple{(:N1, :N2), Tuple{Float64, Float64}}}(Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters[Normalized{FExp{NamedTuple{(:α,), Tuple{Float64}}}, Tuple{Int64, Int64}}(FExp{NamedTuple{(:α,), Tuple{Float64}}}((α = -0.2,)), (-4, 7)), Normalized{FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}, Tuple{Int64, Int64}}(FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}((μ = 1.1, σ = 0.9)), (-4, 7))], (N1 = 0.85, N2 = 0.15)), [-3.31363508153481, 0.43447564485962653, -3.745754980204587, 2.9827251235352814, -0.3309369330264057, 1.3895179840798346, -2.0730431973848535, -2.601550355863054, 3.2418979163154678, 1.0415275977312637  …  -2.824345540973799, -2.6897096000868306, 3.068596433247254, 2.371365572747345, 1.7739486408818284, 5.870817862622404, 4.142552947014096, -2.1675924554448596, 6.892216385373105, -0.5515063618655209], -10000.0))</code></pre><p>To fit the model to the data, we need to find the parameter values that minimize the extended NLL. We start by setting initial values for the parameters, most importantly the normalization that is going to be constrained to size of the data set.</p><pre><code class="language-julia hljs">starting_values = let
    Nd = length(data)
    default_values = pars(ext)
    @unpack N1, N2 = default_values
    Nsum = N1 + N2
    merge(default_values, (N1=N1 / Nsum * Nd, N2=N2 / Nsum * Nd))
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(α = -0.2, μ = 1.1, σ = 0.9, N1 = 8500.0, N2 = 1500.0)</code></pre><p>When the optimization to fit the model to the data, using a reasonable guess for the inverse hessian matrix helps the initial steps of the optimization. The diagonal elements of the invesse hessian reflect the typical variation of the parameters. The parameter uncertainties in the minimum are often taken as square root of the diagonal elements.</p><pre><code class="language-julia hljs">@time fit = let
    initial_invH = Diagonal([0.001, 0.01, 0.01, 100, 100]) .+ eps()

    optimize(x -&gt; ext(1.1, x), starting_values |&gt; collect,
        BFGS(; initial_invH=x -&gt; initial_invH,))
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"> * Status: success

 * Candidate solution
    Final objective value:     -5.984703e+04

 * Found with
    Algorithm:     BFGS

 * Convergence measures
    |x - x&#39;|               = 0.00e+00 ≤ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 0.00e+00 ≤ 0.0e+00
    |f(x) - f(x&#39;)|         = 0.00e+00 ≤ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 0.00e+00 ≤ 0.0e+00
    |g(x)|                 = 4.09e-05 ≰ 1.0e-08

 * Work counters
    Seconds run:   4  (vs limit Inf)
    Iterations:    496
    f(x) calls:    1744
    ∇f(x) calls:   1744
</code></pre><p>Once we have the best-fit parameters, we can update our model and compare it to the original data.</p><pre><code class="language-julia hljs">best_model = updatepars(model, NamedTuple{keys(pars(model))}(fit.minimizer))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">FSum{Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters, 2, NamedTuple{(:N1, :N2), Tuple{Float64, Float64}}}(Normalized{T, Tuple{Int64, Int64}} where T&lt;:AbstractFunctionWithParameters[Normalized{FExp{NamedTuple{(:α,), Tuple{Float64}}}, Tuple{Int64, Int64}}(FExp{NamedTuple{(:α,), Tuple{Float64}}}((α = -0.2049006027605486,)), (-4, 7)), Normalized{FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}, Tuple{Int64, Int64}}(FGauss{NamedTuple{(:μ, :σ), Tuple{Float64, Float64}}}((μ = 1.0911615074347791, σ = 0.864618100811283)), (-4, 7))], (N1 = 8539.36745342979, N2 = 1460.6325531903917))</code></pre><p>Plotting the original data, and the best-fit model helps us evaluate the fitting process.</p><pre><code class="language-julia hljs">let
    bins = range(lims(model)..., 100)
    Nd = length(data)

    stephist(data; bins)
    plot!(model, scaletobinneddata(Nd, bins), lab=&quot;original&quot;)
    plot!(best_model, scaletobinneddata(bins), lab=&quot;fit&quot;)

    plot!(best_model[2], scaletobinneddata(bins), fill=0, lab=&quot;signal&quot;)
    plot!(best_model[1], scaletobinneddata(bins), ls=:dash, lab=&quot;background&quot;)
end
savefig(&quot;model_fitting.pdf&quot;)</code></pre><p><a href="../model_fitting.pdf"><img src="../model_fitting.svg" alt="Model Fitting"/></a></p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../api/">API »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Monday 1 April 2024 19:33">Monday 1 April 2024</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
